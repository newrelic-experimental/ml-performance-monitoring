{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5096ee85-a0d8-40aa-abf1-406ccee32daf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# New Relic ML Performance Monitoring - Bring Your Own Data\n",
    "\n",
    "[ml-performance-monitoring](https://github.com/newrelic-experimental/ml-performance-monitoring) provides a Python library for sending machine learning models' inference data and performance metrics into New Relic. \n",
    "<br>\n",
    "By using this package, you can easily and quickly monitor your model, directly from a Jupyter notebook or a cloud service. \n",
    "<br>\n",
    "The package is ML framework agnostic and can be quickly integrated. It is based on the newrelic-telemetry-sdk-python library.\n",
    "<br>\n",
    "It is based on the [newrelic-telemetry-sdk-python](https://github.com/newrelic/newrelic-telemetry-sdk-python) library.\n",
    "\n",
    "\n",
    "This notebook provides an example of sending inference data and metrics of an XGBoost model\n",
    "\n",
    "<U>Note</U>- this notebook uses the libraries:\n",
    "* numpy\n",
    "* pandas\n",
    "* sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f7728",
   "metadata": {},
   "source": [
    "### 0. Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ffa025",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/newrelic-experimental/ml-performance-monitoring.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a32abfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf23f3-4ab0-4e52-9c3a-5c150590cc39",
   "metadata": {},
   "source": [
    "### 1. Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ee9c03-5043-4a26-94e6-5924cf549cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from ml_performance_monitoring.monitor import MLPerformanceMonitoring\n",
    "from ml_performance_monitoring.psi import calculate_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432798ef-1fb1-4006-9510-84c4778454a9",
   "metadata": {},
   "source": [
    "### 2. Load the Iris dataset and split it into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302cf098-c363-4989-90a7-1947340eebc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "X, y = (\n",
    "    iris_dataset[\"data\"],\n",
    "    iris_dataset[\"target\"],\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "X[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212217d-1573-4ccd-98e0-3725800d8274",
   "metadata": {},
   "source": [
    "### 3. Fitting Random Forest Classification model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb62a1bb-28ea-4105-93be-62d0a4c8deaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_selection',\n",
       "                 SelectKBest(k=2, score_func=<function chi2 at 0x16c941ca0>)),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Set up a pipeline with a feature selection preprocessor that\n",
    "# selects the top 2 features to use.\n",
    "# The pipeline then uses a RandomForestClassifier to train the model.\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"feature_selection\", SelectKBest(chi2, k=2)),\n",
    "        (\"classification\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5c717-58d3-4b41-88c3-549a044d7d7d",
   "metadata": {},
   "source": [
    "### 4. Predicting the test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcced287-1691-4fd3-a802-bea65f5edf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       2, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2,\n",
       "       1, 2, 0, 0, 0, 1, 0, 0, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 2, 0, 0, 2,\n",
       "       0, 2, 2, 1, 1, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75601195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'versicolor', 'setosa', 'virginica',\n",
       "       'versicolor', 'virginica', 'setosa', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor',\n",
       "       'setosa', 'versicolor', 'versicolor', 'setosa', 'setosa',\n",
       "       'versicolor', 'versicolor', 'virginica', 'setosa', 'virginica',\n",
       "       'versicolor', 'setosa', 'setosa', 'versicolor', 'virginica',\n",
       "       'versicolor', 'virginica', 'versicolor', 'virginica', 'virginica',\n",
       "       'setosa', 'versicolor', 'setosa', 'versicolor', 'virginica',\n",
       "       'virginica', 'setosa', 'versicolor', 'virginica', 'versicolor',\n",
       "       'virginica', 'setosa', 'setosa', 'setosa', 'versicolor', 'setosa',\n",
       "       'setosa', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'versicolor', 'versicolor', 'virginica', 'versicolor', 'setosa',\n",
       "       'virginica', 'virginica', 'setosa', 'setosa', 'virginica',\n",
       "       'setosa', 'virginica', 'virginica', 'versicolor', 'versicolor',\n",
       "       'virginica', 'versicolor', 'setosa', 'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_names = iris_dataset[\"target_names\"][y_pred]\n",
    "y_pred_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee66de2b-e106-4a81-a5f8-83fb252e55fd",
   "metadata": {},
   "source": [
    "### 5. Record inference data to New Relic\n",
    "\n",
    "The MLPerformanceMonitoring parameters: \n",
    "   * Required parameters:\n",
    "      * `model_name` - must be unique per model\n",
    "      *  `insert_key` - [Get your key](https://one.newrelic.com/launcher/api-keys-ui.api-keys-launcher) (also referenced as `ingest - license`) and set it as environment variable: `NEW_RELIC_INSERT_KEY`.\n",
    "[Click here](https://docs.newrelic.com/docs/apis/intro-apis/new-relic-api-keys/#license-key) for more details and instructions.\n",
    "\n",
    "* Optional parameters:\n",
    "   * `metadata` (dictionary) - will be added to each event (row) of the data \n",
    "   * `send_data_metrics` (boolean) - send data metrics (statistics) to New Relic (False as default)\n",
    "   * `features_columns`(list) - the features' names ordered as X columns.\n",
    "   * `labels_columns` (list) - the labels' names ordered as y columns. \n",
    "\n",
    "(note: The parameters `features_columns` and `labels_columns` are only relevant when sending the data as an np.array. When the data is sent as a dataframe, the dataframes (X,y) columns' names will be taken as features and labels names respectively. In addition, if you send your data as an np.array without sending the features_columns and labels_columns, on New Relic data, the names will appear as \"feature_{n}\" and \"lablel_{n}\" numbered by the features/labels order)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709e18a",
   "metadata": {},
   "source": [
    "5.1. Define monitoring parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74dc293-03cb-4e05-99c2-fc88a3c513a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"environment\": \"notebook\", \"dataset\": \"Iris\"}\n",
    "model_version = \"1.0\"\n",
    "features_columns = [\n",
    "    \"sepal_length\",\n",
    "    \"sepal_width\",\n",
    "    \"petal_length\",\n",
    "    \"petal_width\",\n",
    "]\n",
    "\n",
    "labels_columns = [\"species\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba33a366-ab59-4b87-9a2e-0900cfc3a1cf",
   "metadata": {},
   "source": [
    "5.2 Create model monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8638b81c-a85b-4901-a7ec-9f46b84dd259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "insert_key = None\n",
    "\n",
    "ml_monitor = MLPerformanceMonitoring(\n",
    "    insert_key=insert_key,  # set the environment variable NEW_RELIC_INSERT_KEY or send your insert key here\n",
    "    model_name=\"RandomForestClassifier on Iris Dataset\",\n",
    "    metadata=metadata,\n",
    "    send_data_metrics=True,\n",
    "    features_columns=features_columns,\n",
    "    labels_columns=labels_columns,\n",
    "    model_version=model_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f6f13d-83f4-43e3-ab8c-8f027e4fa723",
   "metadata": {},
   "source": [
    "5.3  Send your inference data as an np.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4741c115-f94f-4867-9249-17fc39119089",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_monitor.record_inference_data(X=X_test, y=y_pred_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07124c7-98b6-45fc-83c8-ae8a1d7d7ee8",
   "metadata": {},
   "source": [
    "5.4  Send your inference data as a pd.DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a8a252-675f-4f17-a325-6c940a0ad4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.8          4.0           1.2          0.2\n",
       "1           5.1          2.5           3.0          1.1\n",
       "2           6.6          3.0           4.4          1.4\n",
       "3           5.4          3.9           1.3          0.4\n",
       "4           7.9          3.8           6.4          2.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(\n",
    "    list(map(np.ravel, X_test)),\n",
    "    columns=features_columns,\n",
    ")\n",
    "\n",
    "y_pred_df = pd.DataFrame(\n",
    "    list(map(np.ravel, y_pred_names)),\n",
    "    columns=labels_columns,\n",
    ")\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8f58775-0e59-4689-8c9c-48a8704ad0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species\n",
       "0      setosa\n",
       "1  versicolor\n",
       "2  versicolor\n",
       "3      setosa\n",
       "4   virginica"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf674cc-835e-4ea1-9402-20fd689b2096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_monitor.record_inference_data(X=X_df, y=y_pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd79a4-335e-46f1-b28b-b0e4da4081ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 6. Record metrics to New Relic\n",
    "You can stream custom metrics to New Relic, monitoring your model performance, model data and drift metrics. These metrics will be sent to NRDB as [metric data](https://docs.newrelic.com/docs/data-apis/ingest-apis/metric-api/introduction-metric-api/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dae00f-bafe-46e2-9b79-11a561e3ea86",
   "metadata": {},
   "source": [
    "6.1.  model performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc20d627-9357-498f-a609-81636bb20358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy    : 0.9466666666666667\n",
      "Recall      : 0.9466666666666667\n",
      "Precision   : 0.9486769230769231\n",
      "F1 Score    : 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "# Model Evaluation\n",
    "ac_sc = accuracy_score(y_test, y_pred)\n",
    "rc_sc = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "pr_sc = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "f1_sc = f1_score(y_test, y_pred, average=\"micro\")\n",
    "\n",
    "print(f\"Accuracy    : {ac_sc}\")\n",
    "print(f\"Recall      : {rc_sc}\")\n",
    "print(f\"Precision   : {pr_sc}\")\n",
    "print(f\"F1 Score    : {f1_sc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36710290-5eae-4bc3-b04b-f77a26c053ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"Accuracy\": ac_sc,\n",
    "    \"Recall\": rc_sc,\n",
    "    \"Precision\": pr_sc,\n",
    "    \"F1_Score\": f1_sc,\n",
    "}\n",
    "metrics\n",
    "ml_monitor.record_metrics(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b69928d-e76f-4dbe-9827-906dcd110089",
   "metadata": {},
   "source": [
    "<b> 6.2.  drift metrics</b>\n",
    "<br>\n",
    "send your model drift metric of data drift mertics (need to add the feature_name as variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b8250a-0ab5-487a-abd9-fd50a87a3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate psi for top features\n",
    "df_validation = np.transpose(X_test)\n",
    "df_training = np.transpose(X_train)\n",
    "top_feature_list = [0, 1, 2, 3]\n",
    "data_drift_metrics = {}\n",
    "psi_list = []\n",
    "for index, feature_name in enumerate(features_columns):\n",
    "    # Assuming you have a validation and training set\n",
    "    psi_t = calculate_psi(\n",
    "        df_validation[index],\n",
    "        df_training[index],\n",
    "        buckettype=\"quantiles\",\n",
    "        buckets=10,\n",
    "        axis=1,\n",
    "    )\n",
    "    ml_monitor.record_metrics(metrics={\"data_drift\": psi_t}, feature_name=feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2d631b4-5c25-4f35-a601-6a3d536670bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drift = calculate_psi(y_pred, y_train, buckettype=\"quantiles\", buckets=10, axis=1)\n",
    "ml_monitor.record_metrics(metrics={\"model_drift\": model_drift})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b658547",
   "metadata": {},
   "source": [
    "### 7. Monitor and alert\n",
    "Done! Check your application in the [New Relic UI](https://one.newrelic.com/nr1-core?filters=%28domain%20%3D%20%27MLOPS%27%20AND%20type%20%3D%20%27MACHINE_LEARNING_MODEL%27%29) to see the real time data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745f3475-dba8-4529-8de5-f770d3d44924",
   "metadata": {},
   "source": [
    "### 8. Optional - Simulate 24 hours of model inference data  \n",
    "As written, the main purpose of this library is to record inference data of a scheduled model in production. By running the cell below, a simulation of inference data of the RandomForest Classifier model on the Iris Dataset will run each hour in the last 24 hours. After running the cell, you can view the data in 2 different places:<br>\n",
    "* **Machine learning model** entity- an entity of the type **machine learning model** is automatically created. You can explore your model entities by selecting **Explorer** on [New Relic One](https://one.newrelic.com/launcher/), and going to the **Machine Learning** section on the left navigation menu.\n",
    "\n",
    "* Example dashboard-follow the [instructions](https://docs.newrelic.com/docs/alerts-applied-intelligence/mlops/bring-your-own/mlops-byo/#use-case) to view the data in the example dashboard.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09c8657-b4b4-4d49-9582-248d5a1673a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    n_estimators=10, criterion=\"entropy\", random_state=0\n",
    ")\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "insert_key = None\n",
    "\n",
    "ml_monitor = MLPerformanceMonitoring(\n",
    "    insert_key=insert_key,  # set the environment variable NEW_RELIC_INSERT_KEY or send your insert key here,\n",
    "    model_name=\"RandomForest Classifier on Iris Dataset - Inference Simulation\",\n",
    "    metadata=metadata,\n",
    "    features_columns=features_columns,\n",
    "    labels_columns=labels_columns,\n",
    "    model_version=model_version,\n",
    ")\n",
    "\n",
    "last_24h_date = datetime.now() - timedelta(hours=24)\n",
    "last_24h_timestamp = int(datetime.timestamp(last_24h_date))\n",
    "\n",
    "for i in range(0, 24, 2):\n",
    "    idx = np.random.choice(np.arange(len(X)), randint(10, 50), replace=False)\n",
    "    X_sample = X[idx]\n",
    "    y_sample = y[idx]\n",
    "\n",
    "    y_pred = classifier.predict(X_sample)\n",
    "\n",
    "    X_df = pd.DataFrame(\n",
    "        list(map(np.ravel, X_sample)),\n",
    "        columns=features_columns,\n",
    "    )\n",
    "\n",
    "    y_pred_df = pd.DataFrame(\n",
    "        list(map(np.ravel, y_pred)),\n",
    "        columns=labels_columns,\n",
    "    )\n",
    "\n",
    "    y_pred_df.loc[y_pred_df.species == 0, \"species\"] = \"setosa\"\n",
    "    y_pred_df.loc[y_pred_df.species == 1, \"species\"] = \"versicolour\"\n",
    "    y_pred_df.loc[y_pred_df.species == 2, \"species\"] = \"virginica\"\n",
    "\n",
    "    ml_monitor.record_inference_data(\n",
    "        X=X_df, y=y_pred_df, timestamp=last_24h_timestamp + i * 3600\n",
    "    )\n",
    "\n",
    "    # Model Evaluation\n",
    "    ac_sc = accuracy_score(y_sample, y_pred)\n",
    "    rc_sc = recall_score(y_sample, y_pred, average=\"weighted\")\n",
    "    pr_sc = precision_score(y_sample, y_pred, average=\"weighted\")\n",
    "    f1_sc = f1_score(y_sample, y_pred, average=\"micro\")\n",
    "\n",
    "    ## Calculate psi for top features\n",
    "    df_validation = np.transpose(X_test)\n",
    "    df_training = np.transpose(X_train)\n",
    "    top_feature_list = [0, 1, 2, 3]\n",
    "    data_drift_metrics = {}\n",
    "    psi_list = []\n",
    "    for index, feature_name in enumerate(features_columns):\n",
    "        # Assuming you have a validation and training set\n",
    "        psi_t = calculate_psi(\n",
    "            df_validation[index],\n",
    "            df_training[index],\n",
    "            buckettype=\"quantiles\",\n",
    "            buckets=10,\n",
    "            axis=1,\n",
    "        )\n",
    "        ml_monitor.record_metrics(\n",
    "            metrics={\"data_drift\": psi_t},\n",
    "            timestamp=last_24h_timestamp + i * 3600,\n",
    "            feature_name=feature_name,\n",
    "        )\n",
    "\n",
    "    model_drift = calculate_psi(\n",
    "        y_pred, y_train, buckettype=\"quantiles\", buckets=10, axis=1\n",
    "    )\n",
    "\n",
    "    metrics = {\n",
    "        \"Accuracy\": ac_sc,\n",
    "        \"Recall\": rc_sc,\n",
    "        \"Precision\": pr_sc,\n",
    "        \"F1_Score\": f1_sc,\n",
    "        \"model_drift\": model_drift,\n",
    "    }\n",
    "    metrics\n",
    "    ml_monitor.record_metrics(metrics=metrics, timestamp=last_24h_timestamp + i * 3600)\n",
    "\n",
    "    X_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
